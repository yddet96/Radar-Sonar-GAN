# -*- coding: utf-8 -*-
"""radar_gan_keras.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HZK8f7F7KZy5R8fJSQTroZuB9HAJXcx9
"""

import tensorflow as tf
from tensorflow.keras import layers
import numpy as np
from matplotlib import pyplot as plt
# import pickle
import os
from google.colab import files
from google.colab import drive


def main():
  drive.mount("/content/gdrive")
  print("Initializing...")

  '''
  Load data.
  '''
  print("\tloading data")
  data = np.load("/content/gdrive/My Drive/MS Project/norm_data.npy", mmap_mode = "r")
  
  x_sz = 1547520
  z_sz = 100
  M = 500

  std = 0.001
  d_filters = [1,1,1]
  batch_size = 2

  epochs = 30

  '''
  Define placeholders
  '''
  z = tf.placeholder( tf.float32, shape = (None, z_sz) )
  x = tf.placeholder( tf.float32, shape = (None, x_sz, 2) )
  
  '''
  Define Generator
  '''
  G = tf.keras.models.Sequential([
      layers.Dense(4260, activation = tf.nn.leaky_relu, input_dim = z_sz),
      layers.Reshape([355,12,1]),
      layers.Conv2DTranspose(filters = 16, kernel_size = [4,4], activation = tf.nn.leaky_relu),
      layers.Conv2DTranspose(filters = 32, kernel_size = [16,16], activation = tf.nn.leaky_relu),
      layers.Conv2DTranspose(filters = 64, kernel_size = [16,16], activation = tf.nn.leaky_relu),
      layers.Conv2DTranspose(filters = 128, kernel_size = [16,16]),
      layers.Reshape([x_sz, 2])
  ])
  
  
  '''
  Define Discriminator
  '''
  D = tf.keras.models.Sequential([
      layers.Reshape([1860,1664,1], input_shape = [x_sz,2]),
      layers.Conv2D(filters = d_filters[0], kernel_size = [23,23], strides = [4,4], activation = tf.nn.leaky_relu),
      layers.Conv2D(filters = d_filters[1], kernel_size = [23,23], strides = [4,4], activation = tf.nn.leaky_relu),
      layers.Conv2D(filters = d_filters[2], kernel_size = [23,23], strides = [4,4], activation = tf.nn.leaky_relu),
      layers.Flatten(),
      layers.Dense(100, activation = tf.nn.leaky_relu),
      layers.Dense(1, activation = tf.nn.sigmoid)
  ])
  
  
  '''
  Define Adversarial model
  '''
  AM = tf.keras.models.Sequential([G, D])
  
  G.compile(optimizer = "adam", loss = "binary_crossentropy", metrics = ["accuracy"])
  D.compile(optimizer = "adam", loss = "binary_crossentropy", metrics = ["accuracy"])
  AM.compile(optimizer = "adam", loss = "binary_crossentropy", metrics = ["accuracy"])

  '''
  Training
  '''
  print("Training...")
  
  max_iter = 1
  for i in range(max_iter):
    # Select random real samples
    idx_list = np.random.randint(0, M, size = batch_size)
    real_samples = data[idx_list, :,:]

    # Generate random samples with the generator
    z = np.random.normal(size = [batch_size, z_sz])
    fake_samples = G.predict(z)

    # Construct this batch dataset and assign proper labels to each sample
    x = np.concatenate([real_samples, fake_samples], axis = 0)
    y = np.ones([batch_size*2,1])
    y[batch_size:,:] = 0

    # Train discriminator
    d_loss = D.train_on_batch(x,y)
    print("\n\tD loss: %f \tD accuracy: %f" % (d_loss[0],d_loss[1]))

    # Generate new samples and assign propper labels
    x = np.random.normal(size = [batch_size, z_sz]).astype(np.float32)
    y = np.ones([batch_size, 1]).astype(np.float32)

    # Train generator
    a_loss = AM.train_on_batch(x,y)

    print("\tA loss: %f \tA accuracy: %f" % (a_loss[0],a_loss[1]))
  
  
  return()



if __name__ == "__main__":
  main()